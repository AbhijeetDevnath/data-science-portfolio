{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29f2208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BANK TRANSACTION FRAUD DETECTION SYSTEM\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "FRAUD DETECTION ML PIPELINE\n",
      "==================================================\n",
      "Loading dataset...\n",
      "No local dataset found.So Downloading from Kaggle...\n",
      "[OK] Dataset downloaded to: C:\\Users\\Abhi\\.cache\\kagglehub\\datasets\\valakhorasani\\bank-transaction-dataset-for-fraud-detection\\versions\\4\n",
      "Loading CSV file: bank_transactions_data_2.csv\n",
      "[OK] Dataset loaded successfully from Kaggle!\n",
      "\n",
      "Dataset shape: (2512, 16)\n",
      "\n",
      "First few rows:\n",
      "  TransactionID AccountID  TransactionAmount      TransactionDate  \\\n",
      "0      TX000001   AC00128              14.09  2023-04-11 16:29:14   \n",
      "1      TX000002   AC00455             376.24  2023-06-27 16:44:19   \n",
      "2      TX000003   AC00019             126.29  2023-07-10 18:16:08   \n",
      "3      TX000004   AC00070             184.50  2023-05-05 16:32:11   \n",
      "4      TX000005   AC00411              13.45  2023-10-16 17:51:24   \n",
      "\n",
      "  TransactionType   Location DeviceID      IP Address MerchantID Channel  \\\n",
      "0           Debit  San Diego  D000380  162.198.218.92       M015     ATM   \n",
      "1           Debit    Houston  D000051     13.149.61.4       M052     ATM   \n",
      "2           Debit       Mesa  D000235  215.97.143.157       M009  Online   \n",
      "3           Debit    Raleigh  D000187  200.13.225.150       M002  Online   \n",
      "4          Credit    Atlanta  D000308    65.164.3.100       M091  Online   \n",
      "\n",
      "   CustomerAge CustomerOccupation  TransactionDuration  LoginAttempts  \\\n",
      "0           70             Doctor                   81              1   \n",
      "1           68             Doctor                  141              1   \n",
      "2           19            Student                   56              1   \n",
      "3           26            Student                   25              1   \n",
      "4           26            Student                  198              1   \n",
      "\n",
      "   AccountBalance PreviousTransactionDate  \n",
      "0         5112.21     2024-11-04 08:08:08  \n",
      "1        13758.91     2024-11-04 08:09:35  \n",
      "2         1122.35     2024-11-04 08:07:04  \n",
      "3         8569.06     2024-11-04 08:09:06  \n",
      "4         7429.40     2024-11-04 08:06:39  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2512 entries, 0 to 2511\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   TransactionID            2512 non-null   str    \n",
      " 1   AccountID                2512 non-null   str    \n",
      " 2   TransactionAmount        2512 non-null   float64\n",
      " 3   TransactionDate          2512 non-null   str    \n",
      " 4   TransactionType          2512 non-null   str    \n",
      " 5   Location                 2512 non-null   str    \n",
      " 6   DeviceID                 2512 non-null   str    \n",
      " 7   IP Address               2512 non-null   str    \n",
      " 8   MerchantID               2512 non-null   str    \n",
      " 9   Channel                  2512 non-null   str    \n",
      " 10  CustomerAge              2512 non-null   int64  \n",
      " 11  CustomerOccupation       2512 non-null   str    \n",
      " 12  TransactionDuration      2512 non-null   int64  \n",
      " 13  LoginAttempts            2512 non-null   int64  \n",
      " 14  AccountBalance           2512 non-null   float64\n",
      " 15  PreviousTransactionDate  2512 non-null   str    \n",
      "dtypes: float64(2), int64(3), str(11)\n",
      "memory usage: 314.1 KB\n",
      "None\n",
      "\n",
      "Missing values:\n",
      "TransactionID              0\n",
      "AccountID                  0\n",
      "TransactionAmount          0\n",
      "TransactionDate            0\n",
      "TransactionType            0\n",
      "Location                   0\n",
      "DeviceID                   0\n",
      "IP Address                 0\n",
      "MerchantID                 0\n",
      "Channel                    0\n",
      "CustomerAge                0\n",
      "CustomerOccupation         0\n",
      "TransactionDuration        0\n",
      "LoginAttempts              0\n",
      "AccountBalance             0\n",
      "PreviousTransactionDate    0\n",
      "dtype: int64\n",
      "\n",
      "[INFO] No fraud label column found. Generating synthetic fraud labels...\n",
      "\n",
      "==================================================\n",
      "GENERATING SYNTHETIC FRAUD LABELS\n",
      "==================================================\n",
      "\n",
      "Fraud labels generated based on suspicious patterns:\n",
      "- High transaction amounts (> $701.31)\n",
      "- Multiple login attempts (>= 3)\n",
      "- Low account balance vs transaction amount\n",
      "- Long transaction duration (> 185.0 seconds)\n",
      "\n",
      "Fraud distribution:\n",
      "isFraud\n",
      "0    2403\n",
      "1     109\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fraud percentage: 4.34%\n",
      "\n",
      "==================================================\n",
      "PREPROCESSING DATA\n",
      "==================================================\n",
      "\n",
      "Categorical columns found: ['TransactionID', 'AccountID', 'TransactionDate', 'TransactionType', 'Location', 'DeviceID', 'IP Address', 'MerchantID', 'Channel', 'CustomerOccupation', 'PreviousTransactionDate']\n",
      "Encoded column: TransactionID\n",
      "Encoded column: AccountID\n",
      "Encoded column: TransactionDate\n",
      "Encoded column: TransactionType\n",
      "Encoded column: Location\n",
      "Encoded column: DeviceID\n",
      "Encoded column: IP Address\n",
      "Encoded column: MerchantID\n",
      "Encoded column: Channel\n",
      "Encoded column: CustomerOccupation\n",
      "Encoded column: PreviousTransactionDate\n",
      "\n",
      "Using 'isFraud' as target variable\n",
      "\n",
      "Training set size: (2009, 16)\n",
      "Test set size: (503, 16)\n",
      "\n",
      "Data preprocessing completed!\n",
      "\n",
      "==================================================\n",
      "HANDLING CLASS IMBALANCE WITH SMOTE\n",
      "==================================================\n",
      "\n",
      "Original training set distribution:\n",
      "Non-fraud: 1922\n",
      "Fraud: 87\n",
      "\n",
      "After SMOTE:\n",
      "Non-fraud: 1922\n",
      "Fraud: 1922\n",
      "\n",
      "==================================================\n",
      "TRAINING MODELS\n",
      "==================================================\n",
      "\n",
      "1. Training Logistic Regression...\n",
      "   [OK] Completed\n",
      "\n",
      "2. Training Random Forest...\n",
      "   [OK] Completed\n",
      "\n",
      "3. Training XGBoost...\n",
      "   [OK] Completed\n",
      "\n",
      "==================================================\n",
      "MODEL EVALUATION\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Logistic Regression\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       481\n",
      "           1       0.33      0.82      0.47        22\n",
      "\n",
      "    accuracy                           0.92       503\n",
      "   macro avg       0.66      0.87      0.71       503\n",
      "weighted avg       0.96      0.92      0.93       503\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[444  37]\n",
      " [  4  18]]\n",
      "\n",
      "ROC-AUC Score: 0.9579\n",
      "F1 Score: 0.4675\n",
      "\n",
      "==================================================\n",
      "Random Forest\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       481\n",
      "           1       0.70      0.64      0.67        22\n",
      "\n",
      "    accuracy                           0.97       503\n",
      "   macro avg       0.84      0.81      0.83       503\n",
      "weighted avg       0.97      0.97      0.97       503\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[475   6]\n",
      " [  8  14]]\n",
      "\n",
      "ROC-AUC Score: 0.9896\n",
      "F1 Score: 0.6667\n",
      "\n",
      "==================================================\n",
      "XGBoost\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       481\n",
      "           1       0.76      1.00      0.86        22\n",
      "\n",
      "    accuracy                           0.99       503\n",
      "   macro avg       0.88      0.99      0.93       503\n",
      "weighted avg       0.99      0.99      0.99       503\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[474   7]\n",
      " [  0  22]]\n",
      "\n",
      "ROC-AUC Score: 0.9992\n",
      "F1 Score: 0.8627\n",
      "\n",
      "==================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "==================================================\n",
      "[OK] Saved ROC curves to 'roc_curves.png'\n",
      "[OK] Saved confusion matrices to 'confusion_matrices.png'\n",
      "[OK] Saved model comparison to 'model_comparison.png'\n",
      "\n",
      "==================================================\n",
      "BEST MODEL\n",
      "==================================================\n",
      "\n",
      "Best Model: XGBoost\n",
      "ROC-AUC Score: 0.9992\n",
      "F1 Score: 0.8627\n",
      "\n",
      "==================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "==================================================\n",
      "\n",
      "Generated files:\n",
      "  - roc_curves.png\n",
      "  - confusion_matrices.png\n",
      "  - model_comparison.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fraud Detection Machine Learning System\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import kagglehub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class FraudDetectionModel:\n",
    "    \"\"\"Main class for fraud detection pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=None, use_kaggle=True):\n",
    "        \"\"\"\n",
    "        Initialize the fraud detection model\n",
    "        \n",
    "        Args:\n",
    "            data_path (str, optional): Path to the CSV dataset. If None, downloads from Kaggle.\n",
    "            use_kaggle (bool): If True and data_path is None, automatically downloads from Kaggle.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.use_kaggle = use_kaggle\n",
    "        self.df = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and display basic information about the dataset\"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        \n",
    "        # If no data path provided, download from Kaggle\n",
    "        if self.data_path is None and self.use_kaggle:\n",
    "            print(\"No local dataset found.So Downloading from Kaggle...\")\n",
    "            try:\n",
    "                # Download dataset from Kaggle using kagglehub\n",
    "                # This downloads the entire dataset and returns the path\n",
    "                import os\n",
    "                dataset_path = kagglehub.dataset_download(\"valakhorasani/bank-transaction-dataset-for-fraud-detection\")\n",
    "                print(f\"[OK] Dataset downloaded to: {dataset_path}\")\n",
    "                \n",
    "                # Find the CSV file in the downloaded dataset\n",
    "                csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]\n",
    "                if not csv_files:\n",
    "                    raise FileNotFoundError(\"No CSV file found in the downloaded dataset\")\n",
    "                \n",
    "                csv_file = os.path.join(dataset_path, csv_files[0])\n",
    "                print(f\"Loading CSV file: {csv_files[0]}\")\n",
    "                self.df = pd.read_csv(csv_file)\n",
    "                print(\"[OK] Dataset loaded successfully from Kaggle!\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading from Kaggle: {e}\")\n",
    "                print(\"\\nPlease ensure you have:\")\n",
    "                print(\"1. Kaggle API credentials set up (~/.kaggle/kaggle.json)\")\n",
    "                print(\"2. Or provide a local data_path when creating the model\")\n",
    "                raise\n",
    "        else:\n",
    "            # Load from local file\n",
    "            print(f\"Loading from local file: {self.data_path}\")\n",
    "            self.df = pd.read_csv(self.data_path)\n",
    "        \n",
    "        print(f\"\\nDataset shape: {self.df.shape}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(self.df.head())\n",
    "        print(f\"\\nDataset info:\")\n",
    "        print(self.df.info())\n",
    "        print(f\"\\nMissing values:\")\n",
    "        print(self.df.isnull().sum())\n",
    "        \n",
    "        # Check for fraud distribution\n",
    "        if 'isFraud' in self.df.columns:\n",
    "            print(f\"\\nFraud distribution:\")\n",
    "            print(self.df['isFraud'].value_counts())\n",
    "            print(f\"\\nFraud percentage: {self.df['isFraud'].mean() * 100:.2f}%\")\n",
    "        else:\n",
    "            print(\"\\n[INFO] No fraud label column found. Generating synthetic fraud labels...\")\n",
    "            self.generate_fraud_labels()\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def generate_fraud_labels(self):\n",
    "        \"\"\"Generate synthetic fraud labels based on suspicious patterns\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GENERATING SYNTHETIC FRAUD LABELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Create fraud labels based on suspicious patterns\n",
    "        \n",
    "        fraud_indicators = []\n",
    "        \n",
    "        # High transaction amounts (top 10%)\n",
    "        high_amount_threshold = self.df['TransactionAmount'].quantile(0.90)\n",
    "        fraud_indicators.append(self.df['TransactionAmount'] > high_amount_threshold)\n",
    "        \n",
    "        # Multiple login attempts (>= 3)\n",
    "        fraud_indicators.append(self.df['LoginAttempts'] >= 3)\n",
    "        \n",
    "        # Low account balance with high transaction\n",
    "        low_balance = self.df['AccountBalance'] < self.df['TransactionAmount']\n",
    "        fraud_indicators.append(low_balance)\n",
    "        \n",
    "        # Long transaction duration (top 15%)\n",
    "        long_duration_threshold = self.df['TransactionDuration'].quantile(0.85)\n",
    "        fraud_indicators.append(self.df['TransactionDuration'] > long_duration_threshold)\n",
    "        \n",
    "        # Combine indicators: fraud if 2 or more suspicious patterns\n",
    "        fraud_score = sum(fraud_indicators)\n",
    "        self.df['isFraud'] = (fraud_score >= 2).astype(int)\n",
    "        \n",
    "        print(f\"\\nFraud labels generated based on suspicious patterns:\")\n",
    "        print(f\"- High transaction amounts (> ${high_amount_threshold:.2f})\")\n",
    "        print(f\"- Multiple login attempts (>= 3)\")\n",
    "        print(f\"- Low account balance vs transaction amount\")\n",
    "        print(f\"- Long transaction duration (> {long_duration_threshold} seconds)\")\n",
    "        print(f\"\\nFraud distribution:\")\n",
    "        print(self.df['isFraud'].value_counts())\n",
    "        print(f\"\\nFraud percentage: {self.df['isFraud'].mean() * 100:.2f}%\")\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the data: handle missing values, encode categoricals, scale features\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PREPROCESSING DATA\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Make a copy to avoid modifying original\n",
    "        df_processed = self.df.copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        df_processed = df_processed.fillna(df_processed.median(numeric_only=True))\n",
    "        \n",
    "        # Identify categorical columns\n",
    "        categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "        print(f\"\\nCategorical columns found: {categorical_cols}\")\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        label_encoders = {}\n",
    "        for col in categorical_cols:\n",
    "            if col in df_processed.columns:\n",
    "                le = LabelEncoder()\n",
    "                df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "                label_encoders[col] = le\n",
    "                print(f\"Encoded column: {col}\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        # Common fraud column names\n",
    "        fraud_col = None\n",
    "        for col in ['isFraud', 'is_fraud', 'fraud', 'Fraud', 'Class']:\n",
    "            if col in df_processed.columns:\n",
    "                fraud_col = col\n",
    "                break\n",
    "        \n",
    "        if fraud_col is None:\n",
    "            raise ValueError(\"Could not find fraud label column. Please ensure dataset has 'isFraud' or similar column.\")\n",
    "        \n",
    "        print(f\"\\nUsing '{fraud_col}' as target variable\")\n",
    "        \n",
    "        X = df_processed.drop(columns=[fraud_col])\n",
    "        y = df_processed[fraud_col]\n",
    "        \n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTraining set size: {self.X_train.shape}\")\n",
    "        print(f\"Test set size: {self.X_test.shape}\")\n",
    "        \n",
    "        # Scale features\n",
    "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "        \n",
    "        print(\"\\nData preprocessing completed!\")\n",
    "        \n",
    "    def handle_imbalance(self):\n",
    "        \"\"\"Handle class imbalance using SMOTE\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"HANDLING CLASS IMBALANCE WITH SMOTE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(f\"\\nOriginal training set distribution:\")\n",
    "        print(f\"Non-fraud: {sum(self.y_train == 0)}\")\n",
    "        print(f\"Fraud: {sum(self.y_train == 1)}\")\n",
    "        \n",
    "        smote = SMOTE(random_state=42)\n",
    "        self.X_train, self.y_train = smote.fit_resample(self.X_train, self.y_train)\n",
    "        \n",
    "        print(f\"\\nAfter SMOTE:\")\n",
    "        print(f\"Non-fraud: {sum(self.y_train == 0)}\")\n",
    "        print(f\"Fraud: {sum(self.y_train == 1)}\")\n",
    "        \n",
    "    def train_models(self):\n",
    "        \"\"\"Train multiple ML models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING MODELS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Logistic Regression\n",
    "        print(\"\\n1. Training Logistic Regression...\")\n",
    "        lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        lr.fit(self.X_train, self.y_train)\n",
    "        self.models['Logistic Regression'] = lr\n",
    "        print(\"   [OK] Completed\")\n",
    "        \n",
    "        # Random Forest\n",
    "        print(\"\\n2. Training Random Forest...\")\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        rf.fit(self.X_train, self.y_train)\n",
    "        self.models['Random Forest'] = rf\n",
    "        print(\"   [OK] Completed\")\n",
    "        \n",
    "        # XGBoost\n",
    "        print(\"\\n3. Training XGBoost...\")\n",
    "        xgb_model = xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            eval_metric='logloss',\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "        xgb_model.fit(self.X_train, self.y_train)\n",
    "        self.models['XGBoost'] = xgb_model\n",
    "        print(\"   [OK] Completed\")\n",
    "        \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"MODEL EVALUATION\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"{name}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            y_pred_proba = model.predict_proba(self.X_test)[:, 1]\n",
    "            \n",
    "            # Metrics\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(self.y_test, y_pred))\n",
    "            \n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            cm = confusion_matrix(self.y_test, y_pred)\n",
    "            print(cm)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            roc_auc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "            f1 = f1_score(self.y_test, y_pred)\n",
    "            \n",
    "            print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
    "            print(f\"F1 Score: {f1:.4f}\")\n",
    "            \n",
    "            # Store results\n",
    "            self.results[name] = {\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba,\n",
    "                'roc_auc': roc_auc,\n",
    "                'f1_score': f1,\n",
    "                'confusion_matrix': cm\n",
    "            }\n",
    "    \n",
    "    def plot_results(self):\n",
    "        \"\"\"Create visualization plots for model performance\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"GENERATING VISUALIZATIONS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # ROC Curves\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for name, results in self.results.items():\n",
    "            fpr, tpr, _ = roc_curve(self.y_test, results['probabilities'])\n",
    "            plt.plot(fpr, tpr, label=f\"{name} (AUC = {results['roc_auc']:.4f})\")\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Fraud Detection Models')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"[OK] Saved ROC curves to 'roc_curves.png'\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Confusion Matrices\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        for idx, (name, results) in enumerate(self.results.items()):\n",
    "            sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', \n",
    "                       cmap='Blues', ax=axes[idx])\n",
    "            axes[idx].set_title(f'{name}\\nConfusion Matrix')\n",
    "            axes[idx].set_ylabel('Actual')\n",
    "            axes[idx].set_xlabel('Predicted')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"[OK] Saved confusion matrices to 'confusion_matrices.png'\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Model Comparison\n",
    "        model_names = list(self.results.keys())\n",
    "        roc_scores = [self.results[name]['roc_auc'] for name in model_names]\n",
    "        f1_scores = [self.results[name]['f1_score'] for name in model_names]\n",
    "        \n",
    "        x = np.arange(len(model_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.bar(x - width/2, roc_scores, width, label='ROC-AUC', alpha=0.8)\n",
    "        ax.bar(x + width/2, f1_scores, width, label='F1-Score', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Models')\n",
    "        ax.set_ylabel('Scores')\n",
    "        ax.set_title('Model Performance Comparison')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(model_names)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"[OK] Saved model comparison to 'model_comparison.png'\")\n",
    "        plt.close()\n",
    "        \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Return the best performing model based on ROC-AUC score\"\"\"\n",
    "        best_model_name = max(self.results, key=lambda x: self.results[x]['roc_auc'])\n",
    "        best_model = self.models[best_model_name]\n",
    "        best_score = self.results[best_model_name]['roc_auc']   \n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"BEST MODEL\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"\\nBest Model: {best_model_name}\")\n",
    "        print(f\"ROC-AUC Score: {best_score:.4f}\")\n",
    "        print(f\"F1 Score: {self.results[best_model_name]['f1_score']:.4f}\")\n",
    "        \n",
    "        return best_model_name, best_model\n",
    "    \n",
    "    def run_pipeline(self, use_smote=True):\n",
    "        \"\"\"Run the complete fraud detection pipeline\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"FRAUD DETECTION ML PIPELINE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Load data\n",
    "        self.load_data()\n",
    "        \n",
    "        # Preprocess\n",
    "        self.preprocess_data()\n",
    "        \n",
    "        # Handle imbalance\n",
    "        if use_smote:\n",
    "            self.handle_imbalance()\n",
    "        \n",
    "        # Train models\n",
    "        self.train_models()\n",
    "        \n",
    "        # Evaluate\n",
    "        self.evaluate_models()\n",
    "        \n",
    "        # Visualize\n",
    "        self.plot_results()\n",
    "        \n",
    "        # Get best model\n",
    "        self.get_best_model()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\nGenerated files:\")\n",
    "        print(\"  - roc_curves.png\")\n",
    "        print(\"  - confusion_matrices.png\")\n",
    "        print(\"  - model_comparison.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the fraud detection system\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"BANK TRANSACTION FRAUD DETECTION SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create and run the model\n",
    "    # By default, downloads dataset automatically from Kaggle\n",
    "    # To use a local file instead, pass: FraudDetectionModel(data_path=\"your_file.csv\")\n",
    "    fraud_detector = FraudDetectionModel()\n",
    "    fraud_detector.run_pipeline(use_smote=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
